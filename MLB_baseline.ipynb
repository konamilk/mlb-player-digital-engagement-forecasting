{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLB_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jF6kZTC0u2MaPwrFzh4L-lG0kKBqZR2w",
      "authorship_tag": "ABX9TyNct/tBeW+gGED3u7inw40w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konamilk/mlb-player-digital-engagement-forecasting/blob/main/MLB_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPA0wW76Fp4X"
      },
      "source": [
        "DEBUG = True"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZU8bSwR319T"
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from requests import get\n",
        "  NOTEBOOK = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].split('.')[0]\n",
        "  NOTEBOOK"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtjMBhxrr7X8"
      },
      "source": [
        "from pathlib import Path\n",
        "if 'google.colab' in sys.modules:\n",
        "    INPUT = Path('/content/input/')\n",
        "elif 'kaggle_web_client' in sys.modules:\n",
        "    INPUT = Path('../input/mlb-player-digital-engagement-forecasting')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0JWJatJshsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738f7ff3-04c9-450e-fa1d-5bf877f3202b"
      },
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  !mkdir ~/.kaggle\n",
        "  !cp /content/drive/MyDrive/.kaggle/kaggle.json ~/.kaggle\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "  !pip install kaggle"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwV5_ro8tNS3",
        "outputId": "3b5968f9-c27c-4ddd-cf9a-870ac8525fb8"
      },
      "source": [
        "!pip install git+https://github.com/pfnet-research/xfeat.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/pfnet-research/xfeat.git\n",
            "  Cloning https://github.com/pfnet-research/xfeat.git to /tmp/pip-req-build-7uzqss84\n",
            "  Running command git clone -q https://github.com/pfnet-research/xfeat.git /tmp/pip-req-build-7uzqss84\n",
            "Requirement already satisfied (use --upgrade to upgrade): xfeat==0.1.1 from git+https://github.com/pfnet-research/xfeat.git in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from xfeat==0.1.1) (3.13)\n",
            "Requirement already satisfied: ml_metrics in /usr/local/lib/python3.7/dist-packages (from xfeat==0.1.1) (0.1.4)\n",
            "Requirement already satisfied: optuna>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from xfeat==0.1.1) (2.8.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (from xfeat==0.1.1) (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from xfeat==0.1.1) (0.22.2.post1)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from xfeat==0.1.1) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ml_metrics->xfeat==0.1.1) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ml_metrics->xfeat==0.1.1) (1.19.5)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna>=1.3.0->xfeat==0.1.1) (3.8.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna>=1.3.0->xfeat==0.1.1) (0.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna>=1.3.0->xfeat==0.1.1) (4.41.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna>=1.3.0->xfeat==0.1.1) (20.9)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna>=1.3.0->xfeat==0.1.1) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna>=1.3.0->xfeat==0.1.1) (1.4.18)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna>=1.3.0->xfeat==0.1.1) (1.6.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna>=1.3.0->xfeat==0.1.1) (5.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->xfeat==0.1.1) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ml_metrics->xfeat==0.1.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->ml_metrics->xfeat==0.1.1) (2018.9)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.3.0->xfeat==0.1.1) (2.1.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.3.0->xfeat==0.1.1) (5.6.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.3.0->xfeat==0.1.1) (3.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.3.0->xfeat==0.1.1) (2.4.7)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.3.0->xfeat==0.1.1) (2.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna>=1.3.0->xfeat==0.1.1) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna>=1.3.0->xfeat==0.1.1) (1.1.0)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna>=1.3.0->xfeat==0.1.1) (1.0.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna>=1.3.0->xfeat==0.1.1) (1.1.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->ml_metrics->xfeat==0.1.1) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from PrettyTable>=0.7.2->cliff->optuna>=1.3.0->xfeat==0.1.1) (0.2.5)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=1.3.0->xfeat==0.1.1) (0.4.4)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=1.3.0->xfeat==0.1.1) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=1.3.0->xfeat==0.1.1) (21.2.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=1.3.0->xfeat==0.1.1) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna>=1.3.0->xfeat==0.1.1) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna>=1.3.0->xfeat==0.1.1) (2.0.1)\n",
            "Building wheels for collected packages: xfeat\n",
            "  Building wheel for xfeat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xfeat: filename=xfeat-0.1.1-cp37-none-any.whl size=39635 sha256=ef903a6a62796983a26f0db3ff6c6b13a74be440600e87e9e4a1feb487dd4f8c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4wyabwqs/wheels/82/f3/da/060c6ceac1125aa285b041284b7ec5324be345b865c713da9c\n",
            "Successfully built xfeat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l02aDXrawzZw",
        "outputId": "81ef4399-9f63-46e2-e865-7550a51e8322"
      },
      "source": [
        "if 'google.colab' in sys.modules:\n",
        "  !kaggle competitions download -c mlb-player-digital-engagement-forecasting\n",
        "  !mkdir input\n",
        "  !unzip -o '*.zip' -d ./input/\n",
        "  !rm *.zip\n",
        "  !mv *.csv ./input/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "competition.cpython-37m-x86_64-linux-gnu.so: Skipping, found more recently modified local copy (use --force to force download)\n",
            "__init__.py: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading example_test.csv.zip to /content\n",
            "  0% 0.00/3.96M [00:00<?, ?B/s]\n",
            "100% 3.96M/3.96M [00:00<00:00, 64.7MB/s]\n",
            "Downloading teams.csv to /content\n",
            "  0% 0.00/3.68k [00:00<?, ?B/s]\n",
            "100% 3.68k/3.68k [00:00<00:00, 3.47MB/s]\n",
            "Downloading players.csv to /content\n",
            "  0% 0.00/173k [00:00<?, ?B/s]\n",
            "100% 173k/173k [00:00<00:00, 53.9MB/s]\n",
            "Downloading awards.csv to /content\n",
            "  0% 0.00/820k [00:00<?, ?B/s]\n",
            "100% 820k/820k [00:00<00:00, 92.1MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            "100% 468M/470M [00:04<00:00, 65.1MB/s]\n",
            "100% 470M/470M [00:04<00:00, 105MB/s] \n",
            "Downloading example_sample_submission.csv to /content\n",
            "  0% 0.00/191k [00:00<?, ?B/s]\n",
            "100% 191k/191k [00:00<00:00, 172MB/s]\n",
            "Downloading seasons.csv to /content\n",
            "  0% 0.00/824 [00:00<?, ?B/s]\n",
            "100% 824/824 [00:00<00:00, 725kB/s]\n",
            "mkdir: cannot create directory ‘input’: File exists\n",
            "Archive:  train.csv.zip\n",
            "  inflating: ./input/train.csv       \n",
            "\n",
            "Archive:  example_test.csv.zip\n",
            "  inflating: ./input/example_test.csv  \n",
            "\n",
            "2 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSURoFztw90s"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.utils import data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Sk6gVO7JkG"
      },
      "source": [
        "TRAIN = INPUT/'train.csv'\n",
        "TEAMS = INPUT/'awards.csv'\n",
        "PLAYERS = INPUT/'players.csv'\n",
        "AWARDS = INPUT/'awards.csv'\n",
        "SEASONS = INPUT/'seasons.csv'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh1fdI--UN4X"
      },
      "source": [
        "df = pd.read_csv(TRAIN)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61DsO9JyHKoI"
      },
      "source": [
        "def unpack_json(json_str):\n",
        "    return np.nan if pd.isna(json_str) else pd.read_json(json_str)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOOU2R0YfZRv"
      },
      "source": [
        "import datetime\n",
        "def next_date_as_int(date_as_int: int):\n",
        "  dd = date_as_int % 100\n",
        "  date_as_int = date_as_int // 100\n",
        "  mm = date_as_int % 100\n",
        "  yyyy = date_as_int // 100\n",
        "  dt = datetime.datetime(yyyy, mm, dd)\n",
        "  next_dt = dt + datetime.timedelta(days=1)\n",
        "  return next_dt.year * 10000 + next_dt.month * 100 + next_dt.day\n",
        "\n",
        "\n",
        "def int_date(dt: datetime):\n",
        "  return dt.year * 10000 + dt.month * 100 + dt.day"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_7aEDMgva7c"
      },
      "source": [
        "class TrainDataset(object):\n",
        "  def __init__(self,df_train, batch_size=5):\n",
        "    self.df_train = df_train\n",
        "    self.current = 0\n",
        "    self.batch_size = batch_size\n",
        "    self.df_example_sample_submission = pd.read_csv(INPUT/'example_sample_submission.csv')\n",
        "    self.playerId =  self.df_example_sample_submission[self.df_example_sample_submission.date == self.df_example_sample_submission.date[0]].date_playerId.map(lambda x: int(x.split('_')[1]))\n",
        "    self.playerId.name = 'playerId'\n",
        "  \n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  def __next__(self):\n",
        "    start = self.current * self.batch_size\n",
        "    end = (self.current + 1) * self.batch_size\n",
        "    self.current += 1\n",
        "\n",
        "    if start >= self.df_train.shape[0]:\n",
        "      raise StopIteration()\n",
        "    \n",
        "    dates = self.df_train[start:end].date.unique()\n",
        "\n",
        "    temps = []\n",
        "    for date in dates:\n",
        "      df_temp = pd.DataFrame(self.playerId)\n",
        "      df_temp['date'] = date\n",
        "      df_temp['date_playerId'] = str(next_date_as_int(date)) + '_' + df_temp['playerId'].astype(str)\n",
        "      df_temp['target1'] = 0.0\n",
        "      df_temp['target2'] = 0.0\n",
        "      df_temp['target3'] = 0.0\n",
        "      df_temp['target4'] = 0.0\n",
        "      df_temp = df_temp.drop(['playerId'], axis=1)\n",
        "      temps.append(df_temp)\n",
        "\n",
        "    return  self.df_train[start:end].drop('nextDayPlayerEngagement', axis=1).set_index('date'), pd.concat(temps, axis=0).set_index('date'), self.df_train[start:end].nextDayPlayerEngagement"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLTd2Z7uNqEL"
      },
      "source": [
        "from xfeat import SelectCategorical, LabelEncoder, Pipeline, ConcatCombination, SelectNumerical, \\\n",
        "    ArithmeticCombinations, TargetEncoder, aggregation, GBDTFeatureSelector, GBDTFeatureExplorer\n",
        "\n",
        "class PreProcessor(object):\n",
        "  def __init__(self):\n",
        "    self.label_encoder = Pipeline([\n",
        "      SelectCategorical(exclude_cols=['engagementMetricsDate']),\n",
        "      LabelEncoder(output_suffix=\"\"),\n",
        "      ])\n",
        "    self.df_rosters = pd.DataFrame()\n",
        "\n",
        "  def pre_process(self, df_dairy: pd.DataFrame, df_submission: pd.DataFrame, phase = \"train\") -> pd.DataFrame:\n",
        "\n",
        "    X = df_submission.drop(['target1', 'target2', 'target3', 'target4'], axis=1)\n",
        "    X['today'] = pd.to_datetime(X.index.to_numpy().astype(str))\n",
        "    X['year'] = X['today'].dt.year\n",
        "    X['month'] = X['today'].dt.month\n",
        "    X['day'] = X['today'].dt.day\n",
        "    X['dayofweek'] = X['today'].dt.dayofweek\n",
        "    X['engagementMetricsDate'] = pd.to_datetime(X['date_playerId'].str.split('_', expand = True)[0])\n",
        "    X['playerId'] = X['date_playerId'].str.split('_', expand = True)[1].astype(int)\n",
        "\n",
        "    # join rosters\n",
        "\n",
        "    if df_dairy['rosters'].notnull().sum() > 0:\n",
        "      df_rosters = pd.concat(map(lambda x: unpack_json(x), df_dairy[df_dairy['rosters'].notnull()]['rosters']), axis=0)\n",
        "      df_rosters['gameDate'] = pd.to_datetime(df_rosters['gameDate'])\n",
        "      self.df_rosters = pd.concat([self.df_rosters, df_rosters],axis=0)\n",
        "      self.df_rosters = self.df_rosters.drop_duplicates()\n",
        "    X = pd.merge(X, self.df_rosters, how='left', left_on=['today', 'playerId'], right_on=['gameDate', 'playerId']).drop(['status'], axis=1)\n",
        "\n",
        "    # # join player twitter followers\n",
        "    # df_playerTwitterFollowers = pd.concat(map(lambda x: unpack_json(x),df_dairy[df_dairy['playerTwitterFollowers'].notnull()]['playerTwitterFollowers']),axis=0)\n",
        "    # df_playerTwitterFollowers = df_playerTwitterFollowers[['date', 'playerId', 'numberOfFollowers']]\n",
        "    # df_playerTwitterFollowers['year'] = df_playerTwitterFollowers['date'].dt.year\n",
        "    # df_playerTwitterFollowers['month'] = df_playerTwitterFollowers['date'].dt.month\n",
        "    # df_playerTwitterFollowers = df_playerTwitterFollowers.drop('date', axis=1)\n",
        "    # X = pd.merge(X, df_playerTwitterFollowers, how='left', on=['playerId', 'year', 'month'])\n",
        "    # del df_playerTwitterFollowers\n",
        "\n",
        "    # # join team twitter followers\n",
        "    # df_teamTwitterFollowers = pd.concat(map(lambda x: unpack_json(x),df_dairy[df_dairy['teamTwitterFollowers'].notnull()]['teamTwitterFollowers']),axis=0)\n",
        "    # df_teamTwitterFollowers = df_teamTwitterFollowers[['date', 'teamId', 'numberOfFollowers']]\n",
        "    # df_teamTwitterFollowers['year'] = df_teamTwitterFollowers['date'].dt.year\n",
        "    # df_teamTwitterFollowers['month'] = df_teamTwitterFollowers['date'].dt.month\n",
        "    # df_teamTwitterFollowers = df_teamTwitterFollowers.drop('date', axis=1)\n",
        "    # X = pd.merge(X, df_teamTwitterFollowers, how='left', on=['teamId', 'year', 'month'])\n",
        "    # del df_teamTwitterFollowers\n",
        "\n",
        "    # # join games\n",
        "    # df_games = pd.concat(map(lambda x: unpack_json(x),df_dairy[df_dairy['games'].notnull()]['games']),axis=0)\n",
        "    # new_columns = ['gamePk', 'gameType', 'season', 'gameDate', 'gameTimeUTC', 'resumeDate',\n",
        "    #       'resumedFrom', 'codedGameState', 'detailedGameState', 'isTie',\n",
        "    #       'gameNumber', 'doubleHeader', 'dayNight', 'scheduledInnings',\n",
        "    #       'gamesInSeries', 'seriesDescription', 'teamId', 'teamName',\n",
        "    #       'teamAbbrev', 'teamWins', 'teamLosses', 'teamWinPct', 'teamWinner',\n",
        "    #       'teamScore', 'opponentId', 'opponentName', 'opponentAbbrev', 'opponentWins',\n",
        "    #       'opponentLosses', 'opponentWinPct', 'opponentWinner', 'opponentScore']\n",
        "    # df_games_home = df_games.copy()\n",
        "    # df_games_home.columns = new_columns\n",
        "    # df_games_away = df_games.copy()[['gamePk', 'gameType', 'season', 'gameDate', 'gameTimeUTC', 'resumeDate',\n",
        "    #       'resumedFrom', 'codedGameState', 'detailedGameState', 'isTie',\n",
        "    #       'gameNumber', 'doubleHeader', 'dayNight', 'scheduledInnings',\n",
        "    #       'gamesInSeries', 'seriesDescription', 'awayId', 'awayName', 'awayAbbrev', 'awayWins',\n",
        "    #       'awayLosses', 'awayWinPct', 'awayWinner', 'awayScore', 'homeId', 'homeName',\n",
        "    #       'homeAbbrev', 'homeWins', 'homeLosses', 'homeWinPct', 'homeWinner',\n",
        "    #       'homeScore']]\n",
        "    # df_games_away.columns = new_columns\n",
        "    # df_games_2 = pd.concat([df_games_home, df_games_away], axis=0).drop(['teamName', 'teamAbbrev', 'opponentName', 'opponentAbbrev', 'opponentWinner'], axis=1)\n",
        "    # df_games_2['date'] = pd.to_datetime(df_games_2['gameDate'])\n",
        "    # X = pd.merge(X, df_games_2, how='left', on=['teamId', 'date'])\n",
        "    # del new_columns, df_games, df_games_home, df_games_away, df_games_2\n",
        "\n",
        "\n",
        "    # label encoding\n",
        "    if phase == 'train':\n",
        "      X = X.drop(['today', 'date_playerId'], axis=1)\n",
        "      encoded_X = self.label_encoder.fit_transform(X)\n",
        "      X = pd.concat([X['engagementMetricsDate'], encoded_X, SelectNumerical().fit_transform(X)], axis=1)\n",
        "    elif phase == 'eval':\n",
        "      X = X.drop(['today', 'date_playerId'], axis=1)\n",
        "      encoded_X = self.label_encoder.transform(X)\n",
        "      X = pd.concat([X['engagementMetricsDate'], encoded_X, SelectNumerical().fit_transform(X)], axis=1)\n",
        "    \n",
        "    return X\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzmCDV4B1Qeh"
      },
      "source": [
        "# make Traing\n",
        "if DEBUG:\n",
        "  df_train = df[(df.date >= 20200401) & (df.date <= 20210331)]\n",
        "else:\n",
        "  df_train = df[df.date <= 20210331]\n",
        "\n",
        "dts = TrainDataset(df_train, df_train.shape[0])\n",
        "\n",
        "df_dairy, df_submission, targets = next(dts)\n",
        "\n",
        "pre = PreProcessor()\n",
        "\n",
        "X = pre.pre_process(df_dairy, df_submission)\n",
        "\n",
        "# join targets\n",
        "df_targets = pd.concat(map(lambda z: unpack_json(z), targets), axis=0)\n",
        "df_targets['engagementMetricsDate'] = pd.to_datetime(df_targets['engagementMetricsDate'])\n",
        "y = pd.merge(X[['engagementMetricsDate', 'playerId']], df_targets, on=['engagementMetricsDate', 'playerId'], how='left')\n",
        "del df_targets\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UFUAYPPGghj"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiGziG15iykl",
        "outputId": "ec0128ea-59e9-4168-cb64-f23185673691"
      },
      "source": [
        "# make Validation\n",
        "df_valid = df[(df.date >= 20210401) & (df.date <= 20210430)]\n",
        "dts = TrainDataset(df_valid, df_valid.shape[0])\n",
        "\n",
        "df_dairy, df_submission, targets = next(dts)\n",
        "\n",
        "\n",
        "X_val = pre.pre_process(df_dairy, df_submission, phase='eval')\n",
        "df_targets = pd.concat(map(lambda z: unpack_json(z), targets), axis=0)\n",
        "df_targets['engagementMetricsDate'] = pd.to_datetime(df_targets['engagementMetricsDate'])\n",
        "y_val = pd.merge(X_val[['engagementMetricsDate', 'playerId']], df_targets, on=['engagementMetricsDate', 'playerId'], how='left')\n",
        "\n",
        "del df_targets\n",
        "\n",
        "print(df_valid.shape, X_val.shape, y_val.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 12) (35610, 9) (35610, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfs_ChmjRlwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ac98a7-d0db-402e-8254-dcec4db122ca"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQuEYiuyQ7Ia",
        "outputId": "3d3d0f0a-e9f1-43ef-fcc4-9a64a2b4788b"
      },
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "params = {'objective': 'regression',\n",
        "             'metric': 'rmse',\n",
        "             'verbose': -1,\n",
        "             'feature_pre_filter': False,\n",
        "            #  'lambda_l1': 1.9246603611247695,\n",
        "            #  'lambda_l2': 0.0015207873611208637,\n",
        "             'num_leaves': 45,\n",
        "            #  'feature_fraction': 0.616,\n",
        "             'bagging_fraction': 1.0,\n",
        "             'bagging_freq': 0,\n",
        "             'min_child_samples': 20,\n",
        "}\n",
        "\n",
        "target_columns = ['target1', 'target2', 'target3', 'target4']\n",
        "\n",
        "models = []\n",
        "for target_column in target_columns:\n",
        "  lgb_train = lgb.Dataset(X.drop(['engagementMetricsDate'], axis=1), y[target_column])\n",
        "  lgb_valid = lgb.Dataset(X_val.drop(['engagementMetricsDate'], axis=1), y_val[target_column])\n",
        "  model = lgb.train(params, lgb_train, num_boost_round=200, valid_sets=lgb_valid, early_stopping_rounds=10)\n",
        "  models.append(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's rmse: 6.09903\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's rmse: 6.08657\n",
            "[3]\tvalid_0's rmse: 6.07752\n",
            "[4]\tvalid_0's rmse: 6.06476\n",
            "[5]\tvalid_0's rmse: 6.06579\n",
            "[6]\tvalid_0's rmse: 6.06283\n",
            "[7]\tvalid_0's rmse: 6.06054\n",
            "[8]\tvalid_0's rmse: 6.05786\n",
            "[9]\tvalid_0's rmse: 6.05481\n",
            "[10]\tvalid_0's rmse: 6.05356\n",
            "[11]\tvalid_0's rmse: 6.05028\n",
            "[12]\tvalid_0's rmse: 6.04674\n",
            "[13]\tvalid_0's rmse: 6.04575\n",
            "[14]\tvalid_0's rmse: 6.04423\n",
            "[15]\tvalid_0's rmse: 6.04523\n",
            "[16]\tvalid_0's rmse: 6.04564\n",
            "[17]\tvalid_0's rmse: 6.04616\n",
            "[18]\tvalid_0's rmse: 6.04417\n",
            "[19]\tvalid_0's rmse: 6.05065\n",
            "[20]\tvalid_0's rmse: 6.05264\n",
            "[21]\tvalid_0's rmse: 6.05098\n",
            "[22]\tvalid_0's rmse: 6.05723\n",
            "[23]\tvalid_0's rmse: 6.05002\n",
            "[24]\tvalid_0's rmse: 6.04934\n",
            "[25]\tvalid_0's rmse: 6.05539\n",
            "[26]\tvalid_0's rmse: 6.05104\n",
            "[27]\tvalid_0's rmse: 6.04939\n",
            "[28]\tvalid_0's rmse: 6.0483\n",
            "Early stopping, best iteration is:\n",
            "[18]\tvalid_0's rmse: 6.04417\n",
            "[1]\tvalid_0's rmse: 7.7047\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's rmse: 7.69129\n",
            "[3]\tvalid_0's rmse: 7.68286\n",
            "[4]\tvalid_0's rmse: 7.68669\n",
            "[5]\tvalid_0's rmse: 7.67772\n",
            "[6]\tvalid_0's rmse: 7.62657\n",
            "[7]\tvalid_0's rmse: 7.59743\n",
            "[8]\tvalid_0's rmse: 7.57194\n",
            "[9]\tvalid_0's rmse: 7.5209\n",
            "[10]\tvalid_0's rmse: 7.49883\n",
            "[11]\tvalid_0's rmse: 7.46555\n",
            "[12]\tvalid_0's rmse: 7.449\n",
            "[13]\tvalid_0's rmse: 7.4311\n",
            "[14]\tvalid_0's rmse: 7.41749\n",
            "[15]\tvalid_0's rmse: 7.41082\n",
            "[16]\tvalid_0's rmse: 7.39446\n",
            "[17]\tvalid_0's rmse: 7.38452\n",
            "[18]\tvalid_0's rmse: 7.38595\n",
            "[19]\tvalid_0's rmse: 7.37575\n",
            "[20]\tvalid_0's rmse: 7.36432\n",
            "[21]\tvalid_0's rmse: 7.37472\n",
            "[22]\tvalid_0's rmse: 7.36877\n",
            "[23]\tvalid_0's rmse: 7.37407\n",
            "[24]\tvalid_0's rmse: 7.37114\n",
            "[25]\tvalid_0's rmse: 7.38093\n",
            "[26]\tvalid_0's rmse: 7.37585\n",
            "[27]\tvalid_0's rmse: 7.37012\n",
            "[28]\tvalid_0's rmse: 7.36721\n",
            "[29]\tvalid_0's rmse: 7.35152\n",
            "[30]\tvalid_0's rmse: 7.36141\n",
            "[31]\tvalid_0's rmse: 7.36141\n",
            "[32]\tvalid_0's rmse: 7.35216\n",
            "[33]\tvalid_0's rmse: 7.35557\n",
            "[34]\tvalid_0's rmse: 7.34368\n",
            "[35]\tvalid_0's rmse: 7.33722\n",
            "[36]\tvalid_0's rmse: 7.33419\n",
            "[37]\tvalid_0's rmse: 7.34417\n",
            "[38]\tvalid_0's rmse: 7.34024\n",
            "[39]\tvalid_0's rmse: 7.337\n",
            "[40]\tvalid_0's rmse: 7.34824\n",
            "[41]\tvalid_0's rmse: 7.35142\n",
            "[42]\tvalid_0's rmse: 7.3457\n",
            "[43]\tvalid_0's rmse: 7.34535\n",
            "[44]\tvalid_0's rmse: 7.34282\n",
            "[45]\tvalid_0's rmse: 7.34322\n",
            "[46]\tvalid_0's rmse: 7.34041\n",
            "Early stopping, best iteration is:\n",
            "[36]\tvalid_0's rmse: 7.33419\n",
            "[1]\tvalid_0's rmse: 5.63684\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's rmse: 5.6235\n",
            "[3]\tvalid_0's rmse: 5.61517\n",
            "[4]\tvalid_0's rmse: 5.60764\n",
            "[5]\tvalid_0's rmse: 5.60254\n",
            "[6]\tvalid_0's rmse: 5.60784\n",
            "[7]\tvalid_0's rmse: 5.60578\n",
            "[8]\tvalid_0's rmse: 5.59785\n",
            "[9]\tvalid_0's rmse: 5.59664\n",
            "[10]\tvalid_0's rmse: 5.58901\n",
            "[11]\tvalid_0's rmse: 5.58739\n",
            "[12]\tvalid_0's rmse: 5.58837\n",
            "[13]\tvalid_0's rmse: 5.58426\n",
            "[14]\tvalid_0's rmse: 5.58338\n",
            "[15]\tvalid_0's rmse: 5.58006\n",
            "[16]\tvalid_0's rmse: 5.57808\n",
            "[17]\tvalid_0's rmse: 5.58016\n",
            "[18]\tvalid_0's rmse: 5.57917\n",
            "[19]\tvalid_0's rmse: 5.57591\n",
            "[20]\tvalid_0's rmse: 5.57471\n",
            "[21]\tvalid_0's rmse: 5.57429\n",
            "[22]\tvalid_0's rmse: 5.57548\n",
            "[23]\tvalid_0's rmse: 5.57443\n",
            "[24]\tvalid_0's rmse: 5.58012\n",
            "[25]\tvalid_0's rmse: 5.5824\n",
            "[26]\tvalid_0's rmse: 5.58351\n",
            "[27]\tvalid_0's rmse: 5.5854\n",
            "[28]\tvalid_0's rmse: 5.58798\n",
            "[29]\tvalid_0's rmse: 5.58776\n",
            "[30]\tvalid_0's rmse: 5.58588\n",
            "[31]\tvalid_0's rmse: 5.58657\n",
            "Early stopping, best iteration is:\n",
            "[21]\tvalid_0's rmse: 5.57429\n",
            "[1]\tvalid_0's rmse: 6.24779\n",
            "Training until validation scores don't improve for 10 rounds.\n",
            "[2]\tvalid_0's rmse: 6.20806\n",
            "[3]\tvalid_0's rmse: 6.17536\n",
            "[4]\tvalid_0's rmse: 6.13816\n",
            "[5]\tvalid_0's rmse: 6.10666\n",
            "[6]\tvalid_0's rmse: 6.0876\n",
            "[7]\tvalid_0's rmse: 6.06767\n",
            "[8]\tvalid_0's rmse: 6.05149\n",
            "[9]\tvalid_0's rmse: 6.0271\n",
            "[10]\tvalid_0's rmse: 6.01646\n",
            "[11]\tvalid_0's rmse: 5.99395\n",
            "[12]\tvalid_0's rmse: 5.98463\n",
            "[13]\tvalid_0's rmse: 5.95567\n",
            "[14]\tvalid_0's rmse: 5.94495\n",
            "[15]\tvalid_0's rmse: 5.93296\n",
            "[16]\tvalid_0's rmse: 5.92486\n",
            "[17]\tvalid_0's rmse: 5.92277\n",
            "[18]\tvalid_0's rmse: 5.91538\n",
            "[19]\tvalid_0's rmse: 5.91049\n",
            "[20]\tvalid_0's rmse: 5.90532\n",
            "[21]\tvalid_0's rmse: 5.89847\n",
            "[22]\tvalid_0's rmse: 5.87409\n",
            "[23]\tvalid_0's rmse: 5.8744\n",
            "[24]\tvalid_0's rmse: 5.86115\n",
            "[25]\tvalid_0's rmse: 5.85803\n",
            "[26]\tvalid_0's rmse: 5.8473\n",
            "[27]\tvalid_0's rmse: 5.83822\n",
            "[28]\tvalid_0's rmse: 5.83125\n",
            "[29]\tvalid_0's rmse: 5.82327\n",
            "[30]\tvalid_0's rmse: 5.81689\n",
            "[31]\tvalid_0's rmse: 5.81954\n",
            "[32]\tvalid_0's rmse: 5.81731\n",
            "[33]\tvalid_0's rmse: 5.81095\n",
            "[34]\tvalid_0's rmse: 5.8081\n",
            "[35]\tvalid_0's rmse: 5.80291\n",
            "[36]\tvalid_0's rmse: 5.80353\n",
            "[37]\tvalid_0's rmse: 5.79433\n",
            "[38]\tvalid_0's rmse: 5.79507\n",
            "[39]\tvalid_0's rmse: 5.77928\n",
            "[40]\tvalid_0's rmse: 5.77924\n",
            "[41]\tvalid_0's rmse: 5.77483\n",
            "[42]\tvalid_0's rmse: 5.7767\n",
            "[43]\tvalid_0's rmse: 5.76744\n",
            "[44]\tvalid_0's rmse: 5.76282\n",
            "[45]\tvalid_0's rmse: 5.76349\n",
            "[46]\tvalid_0's rmse: 5.76584\n",
            "[47]\tvalid_0's rmse: 5.74485\n",
            "[48]\tvalid_0's rmse: 5.73413\n",
            "[49]\tvalid_0's rmse: 5.72711\n",
            "[50]\tvalid_0's rmse: 5.72681\n",
            "[51]\tvalid_0's rmse: 5.72346\n",
            "[52]\tvalid_0's rmse: 5.7141\n",
            "[53]\tvalid_0's rmse: 5.71698\n",
            "[54]\tvalid_0's rmse: 5.71066\n",
            "[55]\tvalid_0's rmse: 5.70801\n",
            "[56]\tvalid_0's rmse: 5.70765\n",
            "[57]\tvalid_0's rmse: 5.69747\n",
            "[58]\tvalid_0's rmse: 5.69598\n",
            "[59]\tvalid_0's rmse: 5.6919\n",
            "[60]\tvalid_0's rmse: 5.68597\n",
            "[61]\tvalid_0's rmse: 5.6837\n",
            "[62]\tvalid_0's rmse: 5.68112\n",
            "[63]\tvalid_0's rmse: 5.68103\n",
            "[64]\tvalid_0's rmse: 5.68201\n",
            "[65]\tvalid_0's rmse: 5.68018\n",
            "[66]\tvalid_0's rmse: 5.67761\n",
            "[67]\tvalid_0's rmse: 5.67681\n",
            "[68]\tvalid_0's rmse: 5.67095\n",
            "[69]\tvalid_0's rmse: 5.6702\n",
            "[70]\tvalid_0's rmse: 5.66857\n",
            "[71]\tvalid_0's rmse: 5.66289\n",
            "[72]\tvalid_0's rmse: 5.6618\n",
            "[73]\tvalid_0's rmse: 5.66318\n",
            "[74]\tvalid_0's rmse: 5.65967\n",
            "[75]\tvalid_0's rmse: 5.65752\n",
            "[76]\tvalid_0's rmse: 5.65354\n",
            "[77]\tvalid_0's rmse: 5.65347\n",
            "[78]\tvalid_0's rmse: 5.65221\n",
            "[79]\tvalid_0's rmse: 5.65208\n",
            "[80]\tvalid_0's rmse: 5.64315\n",
            "[81]\tvalid_0's rmse: 5.64326\n",
            "[82]\tvalid_0's rmse: 5.6426\n",
            "[83]\tvalid_0's rmse: 5.63646\n",
            "[84]\tvalid_0's rmse: 5.63641\n",
            "[85]\tvalid_0's rmse: 5.63154\n",
            "[86]\tvalid_0's rmse: 5.63163\n",
            "[87]\tvalid_0's rmse: 5.62838\n",
            "[88]\tvalid_0's rmse: 5.62832\n",
            "[89]\tvalid_0's rmse: 5.62492\n",
            "[90]\tvalid_0's rmse: 5.62489\n",
            "[91]\tvalid_0's rmse: 5.62296\n",
            "[92]\tvalid_0's rmse: 5.62358\n",
            "[93]\tvalid_0's rmse: 5.62159\n",
            "[94]\tvalid_0's rmse: 5.62065\n",
            "[95]\tvalid_0's rmse: 5.61929\n",
            "[96]\tvalid_0's rmse: 5.61494\n",
            "[97]\tvalid_0's rmse: 5.61317\n",
            "[98]\tvalid_0's rmse: 5.61248\n",
            "[99]\tvalid_0's rmse: 5.61227\n",
            "[100]\tvalid_0's rmse: 5.61405\n",
            "[101]\tvalid_0's rmse: 5.61434\n",
            "[102]\tvalid_0's rmse: 5.61145\n",
            "[103]\tvalid_0's rmse: 5.61177\n",
            "[104]\tvalid_0's rmse: 5.61253\n",
            "[105]\tvalid_0's rmse: 5.60849\n",
            "[106]\tvalid_0's rmse: 5.60861\n",
            "[107]\tvalid_0's rmse: 5.607\n",
            "[108]\tvalid_0's rmse: 5.60698\n",
            "[109]\tvalid_0's rmse: 5.60544\n",
            "[110]\tvalid_0's rmse: 5.60283\n",
            "[111]\tvalid_0's rmse: 5.60243\n",
            "[112]\tvalid_0's rmse: 5.6024\n",
            "[113]\tvalid_0's rmse: 5.5977\n",
            "[114]\tvalid_0's rmse: 5.59898\n",
            "[115]\tvalid_0's rmse: 5.60015\n",
            "[116]\tvalid_0's rmse: 5.5984\n",
            "[117]\tvalid_0's rmse: 5.59865\n",
            "[118]\tvalid_0's rmse: 5.59862\n",
            "[119]\tvalid_0's rmse: 5.59856\n",
            "[120]\tvalid_0's rmse: 5.59849\n",
            "[121]\tvalid_0's rmse: 5.59704\n",
            "[122]\tvalid_0's rmse: 5.5957\n",
            "[123]\tvalid_0's rmse: 5.59308\n",
            "[124]\tvalid_0's rmse: 5.5912\n",
            "[125]\tvalid_0's rmse: 5.59129\n",
            "[126]\tvalid_0's rmse: 5.59125\n",
            "[127]\tvalid_0's rmse: 5.5917\n",
            "[128]\tvalid_0's rmse: 5.59292\n",
            "[129]\tvalid_0's rmse: 5.59245\n",
            "[130]\tvalid_0's rmse: 5.59112\n",
            "[131]\tvalid_0's rmse: 5.59112\n",
            "[132]\tvalid_0's rmse: 5.59101\n",
            "[133]\tvalid_0's rmse: 5.59248\n",
            "[134]\tvalid_0's rmse: 5.59324\n",
            "[135]\tvalid_0's rmse: 5.59322\n",
            "[136]\tvalid_0's rmse: 5.59277\n",
            "[137]\tvalid_0's rmse: 5.59431\n",
            "[138]\tvalid_0's rmse: 5.59435\n",
            "[139]\tvalid_0's rmse: 5.59636\n",
            "[140]\tvalid_0's rmse: 5.598\n",
            "[141]\tvalid_0's rmse: 5.59836\n",
            "[142]\tvalid_0's rmse: 5.59761\n",
            "Early stopping, best iteration is:\n",
            "[132]\tvalid_0's rmse: 5.59101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ySfF8lpQ62s"
      },
      "source": [
        "if 'google.colab' in sys.modules or 'kaggle_web_client' in sys.modules:\n",
        "  df_test = df[(df.date >= 20210401) & (df.date <= 20210430)]\n",
        "  iter_test = TrainDataset(df_valid, 5)\n",
        "  for df_dairy, df_submission, _ in iter_test:\n",
        "    X = pre.pre_process(df_dairy, df_submission, phase='eval')\n",
        "    X = X.drop('engagementMetricsDate', axis=1)\n",
        "    for (i, model) in enumerate(models):\n",
        "      df_submission[target_columns[i]] = np.clip(model.predict(X), 0.0, 100.0)\n",
        "    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbXJqQyz8byL"
      },
      "source": [
        "if 'kaggle_secrets' in sys.modules:  # only run while on Kaggle\n",
        "  import mlb\n",
        "\n",
        "  env = mlb.make_env()\n",
        "  iter_test = env.iter_test()\n",
        "\n",
        "  for df_dairy, df_submission, _ in iter_test:\n",
        "    X = pre.pre_process(df_dairy, df_submission, phase='eval')\n",
        "    X = X.drop('engagementMetricsDate', axis=1)\n",
        "\n",
        "    for (i, model) in enumerate(models):\n",
        "      df_submission[target_columns[i]] = np.clip(model.predict(X), 0.0, 100.0)\n",
        "\n",
        "    df_submission = df_submission.drop('date', axis=1)\n",
        "    env.predict(df_submission)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrBlCSrdspJ0"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}